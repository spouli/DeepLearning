{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7d0de9b6",
   "metadata": {},
   "source": [
    "# **Sentiment Analysis of IMDB Movie Reviews**\n",
    "\n",
    "</br>\n",
    "\n",
    "**Dataset**\n",
    "</br>\n",
    "\n",
    "The IMDb Dataset of 50K Movie Reviews, is a popular dataset commonly used for sentiment analysis and natural language processing tasks. The dataset consists of 50,000 movie reviews, with 25,000 reviews labeled as positive and 25,000 as negative\n",
    "</br>\n",
    "\n",
    "Dataset Source: [Kaggle](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews?datasetId=134715&searchQuery=pytor)\n",
    "</br>\n",
    "\n",
    "**The Problem Statement**\n",
    "</br>\n",
    "\n",
    "Predict the number of positive and negative reviews based on sentiments by using deep learning techniques.\n",
    "\n",
    "**To approach this problem, we've followed the below outline:**\n",
    "\n",
    "- **Data preprocessing:** applied in the notebook called _\"Data_preprocessing_notebook\"_\n",
    "</br>\n",
    "\n",
    "- **Word embedding:** We've converted the preprocessed text into a numerical representation that can be understood by deep learning models, using word embeddings, such as Word2Vec or GloVe, to represent words as dense vectors in a continuous vector space.\n",
    "</br>\n",
    "\n",
    "- **Model selection:** Choose a suitable deep learning model architecture including recurrent neural networks (RNNs), long short-term memory (LSTM) networks, and convolutional neural networks (CNNs). \n",
    "</br>\n",
    "\n",
    "- **Model training:** Split our dataset into training and validation sets.\n",
    "</br>\n",
    "- **Model evaluation**\n",
    "</br>\n",
    "- **Model refinement**\n",
    "</br>\n",
    "\n",
    "**(Initial) Attributes**:\n",
    "\n",
    "* Review\n",
    "* Sentiment\n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9279f6e6",
   "metadata": {},
   "source": [
    "## All the imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f47b4c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import to \"ignore\" warnings\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# imports for data manipulation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# imports for data visualization\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud # need local import\n",
    "\n",
    "\n",
    "# import pytorch (framework for building deep learning models) || need local import\n",
    "\n",
    "import torch \n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# imports from sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import gensim # need local import\n",
    "import random\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2b80ed48",
   "metadata": {},
   "source": [
    "## Load the csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f059b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one review mention watch oz episod hook right ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonder littl product film techniqu unassum old...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonder way spend time hot summer weeke...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basic famili littl boy jake think zombi closet...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei love time money visual stun film...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  one review mention watch oz episod hook right ...          1\n",
       "1  wonder littl product film techniqu unassum old...          1\n",
       "2  thought wonder way spend time hot summer weeke...          1\n",
       "3  basic famili littl boy jake think zombi closet...          0\n",
       "4  petter mattei love time money visual stun film...          1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data\n",
    "\n",
    "data = pd.read_csv('imdb_clean_dataset.csv')\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd1af4d7",
   "metadata": {},
   "source": [
    "## Word embedding using Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "307dd648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one review mention watch oz episod hook right ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.04266952, 0.15759, 0.08354795, 0.11671276, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonder littl product film techniqu unassum old...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.08034655, 0.116457954, 0.06715829, 0.119105...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonder way spend time hot summer weeke...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.040959258, 0.098045155, 0.033240408, 0.0907...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basic famili littl boy jake think zombi closet...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.004097277, 0.123330146, 0.07372391, 0.11563...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei love time money visual stun film...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.057226174, 0.09773444, 0.090847254, 0.09383...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment  \\\n",
       "0  one review mention watch oz episod hook right ...          1   \n",
       "1  wonder littl product film techniqu unassum old...          1   \n",
       "2  thought wonder way spend time hot summer weeke...          1   \n",
       "3  basic famili littl boy jake think zombi closet...          0   \n",
       "4  petter mattei love time money visual stun film...          1   \n",
       "\n",
       "                                           embedding  \n",
       "0  [0.04266952, 0.15759, 0.08354795, 0.11671276, ...  \n",
       "1  [0.08034655, 0.116457954, 0.06715829, 0.119105...  \n",
       "2  [0.040959258, 0.098045155, 0.033240408, 0.0907...  \n",
       "3  [0.004097277, 0.123330146, 0.07372391, 0.11563...  \n",
       "4  [0.057226174, 0.09773444, 0.090847254, 0.09383...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set a random seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Split the sentences into words\n",
    "sentences = [text.split() for text in data['review']]\n",
    "\n",
    "# Train the Word2Vec model\n",
    "model = gensim.models.Word2Vec(sentences, vector_size=500, window=5, min_count=2, workers=4, sg=1)\n",
    "\n",
    "# Get the word vectors (keys) from the trained model\n",
    "word_vectors = model.wv.index_to_key\n",
    "\n",
    "\n",
    "# Calculate the embeddings for each text in the dataset\n",
    "embeddings = []\n",
    "for text in data['review']:\n",
    "    # Split the text into words\n",
    "    words = text.split()\n",
    "\n",
    "    \n",
    "    # Initialize an empty list to store word vectors for the current text\n",
    "    text_word_vectors = []\n",
    "    \n",
    "    # Iterate over each word in the text\n",
    "    for word in words:\n",
    "        # Check if the word is present in the word vectors of the model\n",
    "        if word in model.wv.key_to_index:\n",
    "            # Retrieve the word vector for the word\n",
    "            vector = model.wv.get_vector(word)\n",
    "            # Append the word vector to the list for the current text\n",
    "            text_word_vectors.append(vector)\n",
    "    \n",
    "    # Check if there are any word vectors for the current text\n",
    "    if text_word_vectors:\n",
    "        # Calculate the average vector for the text\n",
    "        text_embedding = np.mean(text_word_vectors, axis=0)\n",
    "    else:\n",
    "        # If no word vectors are found, assign a zero vector\n",
    "        text_embedding = np.zeros(500)  # or any other suitable dimension\n",
    "    \n",
    "    # Append the text embedding to the list of embeddings\n",
    "    embeddings.append(text_embedding)\n",
    "\n",
    "# Assign the calculated embeddings to the 'embedding' column in the DataFrame\n",
    "data['embedding'] = embeddings\n",
    "\n",
    "\n",
    "data.head()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bb68b9d5",
   "metadata": {},
   "source": [
    "## Split into train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7214647",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train data: (39665,)\n",
      "Shape of test data: (9917,)\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and test sets\n",
    "X_train,X_test,y_train,y_test = train_test_split(data['embedding'], data['sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "print(f'Shape of train data: {X_train.shape}')\n",
    "print(f'Shape of test data: {X_test.shape}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
