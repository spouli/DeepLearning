{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d0de9b6",
   "metadata": {},
   "source": [
    "# **Sentiment Analysis of IMDB Movie Reviews**\n",
    "\n",
    "</br>\n",
    "\n",
    "**Dataset**\n",
    "</br>\n",
    "\n",
    "The IMDb Dataset of 50K Movie Reviews, is a popular dataset commonly used for sentiment analysis and natural language processing tasks. The dataset consists of 50,000 movie reviews, with 25,000 reviews labeled as positive and 25,000 as negative\n",
    "</br>\n",
    "\n",
    "Dataset Source: [Kaggle](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews?datasetId=134715&searchQuery=pytor)\n",
    "</br>\n",
    "\n",
    "**The Problem Statement**\n",
    "</br>\n",
    "\n",
    "Predict the number of positive and negative reviews based on sentiments by using deep learning techniques.\n",
    "\n",
    "**To approach this problem, we've followed the below outline:**\n",
    "\n",
    "- **Data preprocessing:** applied in the notebook called _\"Data_preprocessing_notebook\"_\n",
    "</br>\n",
    "\n",
    "- **Word embedding:** We've converted the preprocessed text into a numerical representation that can be understood by deep learning models, using word embeddings, such as Word2Vec or GloVe, to represent words as dense vectors in a continuous vector space.\n",
    "</br>\n",
    "\n",
    "- **Model selection:** Choose a suitable deep learning model architecture including recurrent neural networks (RNNs), long short-term memory (LSTM) networks, and convolutional neural networks (CNNs). \n",
    "</br>\n",
    "\n",
    "- **Model training:** Split our dataset into training and validation sets.\n",
    "</br>\n",
    "- **Model evaluation**\n",
    "</br>\n",
    "- **Model refinement**\n",
    "</br>\n",
    "\n",
    "**(Initial) Attributes**:\n",
    "\n",
    "* Review\n",
    "* Sentiment\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9279f6e6",
   "metadata": {},
   "source": [
    "## All the imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f47b4c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import to \"ignore\" warnings\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# imports for data manipulation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# imports for data visualization\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud # need local import\n",
    "\n",
    "\n",
    "# import pytorch (framework for building deep learning models) || need local import\n",
    "\n",
    "import torch \n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# imports from sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import gensim # need local import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b80ed48",
   "metadata": {},
   "source": [
    "## Load the csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3f059b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one review mention watch oz episod hook right ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonder littl product film techniqu unassum old...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonder way spend time hot summer weeke...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basic famili littl boy jake think zombi closet...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei love time money visual stun film...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  one review mention watch oz episod hook right ...          1\n",
       "1  wonder littl product film techniqu unassum old...          1\n",
       "2  thought wonder way spend time hot summer weeke...          1\n",
       "3  basic famili littl boy jake think zombi closet...          0\n",
       "4  petter mattei love time money visual stun film...          1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data\n",
    "\n",
    "data = pd.read_csv('imdb_clean_dataset.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1af4d7",
   "metadata": {},
   "source": [
    "## Word embedding using Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c8d741ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one review mention watch oz episod hook right ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.5883391, 0.26740506, -0.4274795, -0.2607590...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonder littl product film techniqu unassum old...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.44789693, 0.22259189, -0.44325185, -0.09301...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonder way spend time hot summer weeke...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.3831304, 0.2718575, -0.4016498, 0.12928088,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basic famili littl boy jake think zombi closet...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.51270556, 0.67743295, -0.75755, -0.13768345...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei love time money visual stun film...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.34306252, 0.2656034, -0.74243355, -0.279398...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment  \\\n",
       "0  one review mention watch oz episod hook right ...          1   \n",
       "1  wonder littl product film techniqu unassum old...          1   \n",
       "2  thought wonder way spend time hot summer weeke...          1   \n",
       "3  basic famili littl boy jake think zombi closet...          0   \n",
       "4  petter mattei love time money visual stun film...          1   \n",
       "\n",
       "                                           embedding  \n",
       "0  [0.5883391, 0.26740506, -0.4274795, -0.2607590...  \n",
       "1  [0.44789693, 0.22259189, -0.44325185, -0.09301...  \n",
       "2  [0.3831304, 0.2718575, -0.4016498, 0.12928088,...  \n",
       "3  [0.51270556, 0.67743295, -0.75755, -0.13768345...  \n",
       "4  [0.34306252, 0.2656034, -0.74243355, -0.279398...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Word2Vec model\n",
    "\n",
    "sentences = []\n",
    "for text in data['review']:\n",
    "    words = text.split()\n",
    "    sentences.append(words)\n",
    "model = gensim.models.Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "word_vectors = model.wv\n",
    "\n",
    "# Convert text to Word2Vec embeddings\n",
    "def text_to_word2vec(text):\n",
    "    word_tokens = text.split()\n",
    "    word_vectors = []\n",
    "    for word in word_tokens:\n",
    "        if word in model.wv.key_to_index:\n",
    "            vector = model.wv.get_vector(word)\n",
    "            word_vectors.append(vector)\n",
    "    if word_vectors:\n",
    "        text_embedding = np.mean(word_vectors, axis=0)\n",
    "    else:\n",
    "        text_embedding = np.zeros(100)  # or any other suitable dimension\n",
    "    return text_embedding\n",
    "\n",
    "# Apply feature engineering to the entire dataset\n",
    "data['embedding'] = data['review'].apply(text_to_word2vec)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb68b9d5",
   "metadata": {},
   "source": [
    "## Split into train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b7214647",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train data: (39665,)\n",
      "Shape of test data: (9917,)\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and test sets\n",
    "X_train,X_test,y_train,y_test = train_test_split(data['embedding'], data['sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "print(f'Shape of train data: {X_train.shape}')\n",
    "print(f'Shape of test data: {X_test.shape}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
